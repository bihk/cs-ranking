{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from csrank.dataset_reader import SyntheticDatasetGenerator\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from csrank.callbacks import DebugOutput, LRScheduler\n",
    "from csrank.tuning import ParameterOptimizer\n",
    "import logging\n",
    "from csrank.util import configure_logging_numpy_keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import os\n",
    "from skopt import load\n",
    "from csrank.objectranking import RankNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the current optimizer and check if some iterations are already done and start after that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the duration in string to the time required in microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(logger, optimizer_path, n_iter):\n",
    "    logger.info('Retrieving model stored at: {}'.format(optimizer_path))\n",
    "    try:\n",
    "        optimizer = load(optimizer_path)\n",
    "        logger.info('Loading model stored at: {}'.format(optimizer_path))\n",
    "\n",
    "    except KeyError:\n",
    "        logger.error('Cannot open the file {}'.format(optimizer_path))\n",
    "        optimizer = None\n",
    "\n",
    "    except ValueError:\n",
    "        logger.error('Cannot open the file {}'.format(optimizer_path))\n",
    "        optimizer = None\n",
    "    except FileNotFoundError:\n",
    "        logger.error('No such file or directory: {}'.format(optimizer_path))\n",
    "        optimizer = None\n",
    "    if optimizer is not None:\n",
    "        finished_iterations = np.array(optimizer.yi).shape[0]\n",
    "        if finished_iterations == 0:\n",
    "            optimizer = None\n",
    "            logger.info('Optimizer did not finish any iterations so setting optimizer to null')\n",
    "        else:\n",
    "            n_iter = n_iter - finished_iterations\n",
    "            if n_iter < 0:\n",
    "                n_iter = 0\n",
    "            logger.info('Iterations already done: {} and running iterations {}'.format(finished_iterations, n_iter))\n",
    "    return optimizer, n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining constants for the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the keras and tensorflow. Defining the parameters for dataset reader. Defining the splits for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = configure_logging_numpy_keras(log_path=os.path.join(os.getcwd(), 'logs' ,\"test_models.log\"), name='Experiment')\n",
    "n_features = 2\n",
    "n_instances = 10000\n",
    "n_objects = 5\n",
    "random_state = check_random_state(42)\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.5, random_state=random_state)\n",
    "epochs = 5\n",
    "optimizer_path = os.path.join(os.getcwd(), 'logs',\"optimizer\")\n",
    "n_iter = 4\n",
    "optimizer, n_iter = get_optimizer(logger, optimizer_path, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_duration_microsecond(duration):\n",
    "    time = int(re.findall(r'\\d+', duration)[0])\n",
    "    d = duration.split(str(time))[1].upper()\n",
    "    options = {\"D\": 24 * 60 * 60 * 1e6, \"H\": 60 * 60 * 1e6, \"M\": 60 * 1e6}\n",
    "    return options[d] * time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Ranker initializing and fitting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_params = {'n_objects': n_objects,\n",
    "                 'n_features':n_features, \n",
    "                 'n_object_features':n_features}\n",
    "ranker = RankNet(**ranker_params)\n",
    "debugOutput = DebugOutput()\n",
    "lrScheduler = LRScheduler(initial_lr=K.get_value(ranker.optimizer.lr))\n",
    "\n",
    "fit_params = {'epochs': epochs,\n",
    "              'callbacks':[debugOutput, lrScheduler]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Parameter optimizer initializing and fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fit_params = {'n_iter': n_iter, \n",
    "                        'cv_iter': skf, \n",
    "                        'optimizer': optimizer, \n",
    "                        \"total_duration\":get_duration_microsecond(\"10h\")}\n",
    "\n",
    "ranker_tunables = dict(n_hidden=(2,20), n_units=(20,40), \n",
    "                        learning_rate=(1e-5, 1e-2, 'log-uniform'),\n",
    "                        reg_strength=(1e-10, 1e-1, 'log-uniform'),\n",
    "                        batch_size=(64, 1024))\n",
    "\n",
    "lrScheduler_tunables = dict(epochs_drop=(300,600), drop=(1e-2, 1e-1, 'log-uniform'))\n",
    "\n",
    "tunable_parameter_ranges = {ranker: ranker_tunables, lrScheduler: lrScheduler_tunables}\n",
    "\n",
    "optimizer_params = {'ranker': ranker,\n",
    "                    'tunable_parameter_ranges': tunable_parameter_ranges,\n",
    "                    'fit_params': fit_params,\n",
    "                    'random_state': random_state, \n",
    "                    \"optimizer_path\": optimizer_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the medoid test and train dataset with defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medoids_params = {'dataset_type': \"medoid\",\n",
    "                  'n_test_instances': n_instances,\n",
    "                  'n_train_instances': n_instances,\n",
    "                  'n_features': n_features,\n",
    "                  'n_objects': n_objects,\n",
    "                  'random_state': random_state}\n",
    "dr = SyntheticDatasetGenerator(**medoids_params)\n",
    "X, Y, X_test, Y_test = dr.get_single_train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_model = ParameterOptimizer(**optimizer_params)\n",
    "optimizer_model.fit(X, Y, **optimizer_fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Ranker with best parameters found by the optimizer on the test dataset\n",
    "Predict Scores for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34003744, 0.40530878, 0.31550464, 0.63641626, 0.63163394],\n",
       "       [0.40763062, 0.48692006, 0.355434  , 0.33623344, 0.4165258 ],\n",
       "       [0.49906975, 0.3731012 , 0.430352  , 0.5236497 , 0.4388348 ],\n",
       "       ...,\n",
       "       [0.50546443, 0.534902  , 0.4652732 , 0.4417104 , 0.4568018 ],\n",
       "       [0.38909936, 0.51279926, 0.34461373, 0.51644784, 0.6094    ],\n",
       "       [0.4558252 , 0.31391865, 0.62172145, 0.6636104 , 0.5680445 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = optimizer_model.predict_scores(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
